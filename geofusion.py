# -*- coding: utf-8 -*-
"""Geofusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uog1ow-jjXRMrmvPnS8TM8SaqYJTRNbP
"""

# ================================
# 0) Imports e configura√ß√µes gerais
# ================================
# Librarias necess√°rias
# Libs para manipula√ß√£o de dados
import pandas as pd
import numpy as np

# Libs graficas ou de Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Libs para Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import joblib

# ler dados corretamente
import unicodedata

# Avisos
# Fun√ß√£o warnings.filterwarnings("ignore") Para evitar o Warning () avisos
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o no pandas
# Fun√ß√£o pandas.set_option() para ajuste de linhas e colunas no () Par√¢metros  (pat, valor)
# pat: Regexp que deve corresponder a uma √∫nica op√ß√£o.
# valor: Novo valor da op√ß√£o.
pd.set_option('display.max_rows', 200)
pd.set_option('display.max_columns', 200)

# Configura√ß√£o no Matplotlib
# Fun√ß√£o plt.rcParams['figure.figsize'] = (12, 6) para ajustar o tamanho padr√£o
# Fun√ß√£o plt.style.use('seaborn-darkgrid') para ajustar o estilo dos gr√°ficos
plt.rcParams['figure.figsize'] = (12, 6)
sns.set_theme(style="darkgrid", context="notebook")  # substitui o antigo 'seaborn-darkgrid'

# Para garantir reprodutibilidade dos resultados
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

"""## 1. Introdu√ß√£o
Este projeto busca prever o faturamento em novos bairros do Rio de Janeiro com base em caracter√≠sticas sociodemogr√°ficas.  
Al√©m disso, busca identificar quais vari√°veis influenciam mais no faturamento.

**Explora√ß√£o dos Dados**
"""

# =====================================
# 1) Carregar os dados no Google Colab
# =====================================
# 1¬™ Op√ß√£o: ler direto do arquivo no ambiente
# Lendo os dados
# Fun√ß√£o de leitura da base de dados importada no colab Base_Dados = pd.read_csv () entre (o nome do arquivo)

# Normalizar nomes de colunas para evitar problemas com acentos/mai√∫sculas
def normalize_colname(c):
    c = c.strip()  # remove espa√ßos extras
    c = unicodedata.normalize("NFKD", c).encode("ascii", "ignore").decode("utf-8")  # remove acentos
    c = c.lower().replace(" ", "_")
    return c

Base_Dados = pd.read_csv('DesafioEstagioMachineLearning.csv')
Base_Dados.columns = [normalize_colname(c) for c in Base_Dados.columns]
print(Base_Dados.columns.tolist())
# 2¬™ Op√ß√£o B (alternativa): subir do seu computador
# from google.colab import files
# uploaded = files.upload()
# CSV_PATH = list(uploaded.keys())[0]

# Dimens√£o
# A a fun√ß√£o Python NumPy numpy.shape() encontra a forma de um array.
# Por shape, queremos dizer que ajuda a encontrar as dimens√µes de um array.
# Retorna a forma sob a forma de um tuple porque n√£o podemos alterar um tuple tal como n√£o podemos alterar as dimens√µes de um array.
Base_Dados.shape

# Corre√ß√£o
Base_Dados = pd.read_csv("DesafioEstagioMachineLearning.csv", encoding="latin1")

# Corrigir nomes de colunas
Base_Dados.rename(columns={"popula√É¬ß√É¬£o": "populacao"}, inplace=True)

"""## 2. Explora√ß√£o dos Dados (EDA)
### 2.1 Estrutura do Dataset
- N√∫mero de linhas e colunas.
- Tipos de vari√°veis.
- Verifica√ß√£o de valores ausentes.
"""

# Verificar
# A fun√ß√£o head() exibe as linhas iniciais da base de dados, se nenhum valor for informado, esta fun√ß√£o vai exibir as cinco primeiras linhas.
print("Dimens√£o:", Base_Dados.shape)
Base_Dados.head()

# Campos unicos
# A fun√ß√£o Nunique, por outro lado, conta os valores distintos das colunas. Os valores NaN podem ser ignorados.
# Isso mostra apenas o n√∫mero de categorias diferentes presentes em uma coluna de um dataframe.
Base_Dados.nunique()

# Tipos das colunas
# A fun√ß√£o Pandas dataframe.info() √© usada para obter um resumo conciso do dataframe, √© muito √∫til para identificar dados NaN.
# Essa fun√ß√£o aplicada sobre um dataframe, retorna uma tabela com informa√ß√µes de cada coluna do dataframe: quantidade de valores n√£o NaN e tipo de dados.
print(Base_Dados.dtypes.value_counts())
Base_Dados.info()

# Tipo de colunas
# A fun√ß√£o .dtypes nos mostra que tipo de dados cada coluna cont√©m
Base_Dados.dtypes.value_counts()

"""###2.2 Estat√≠sticas Descritivas
(Exibir `describe()`).  

**Descri√ß√£o:**  
> As vari√°veis apresentam diferentes escalas. O faturamento varia de X a Y, enquanto a renda m√©dia apresenta lacunas que dever√£o ser tratadas.
"""

# Estat√≠sticas descritivas
print("=== Estat√≠sticas descritivas ===")
print(Base_Dados.describe())

# Contagem de valores nulos
print("\n=== Contagem de valores nulos ===")
print(Base_Dados.isna().sum())

"""### 2.3 Distribui√ß√£o das Vari√°veis (Histogramas)
(Gr√°ficos de histograma para renda, popula√ß√£o, faturamento etc).  

**Descri√ß√£o:**  
> Observa-se que a maioria dos bairros possui faturamento concentrado em uma faixa inferior, com alguns casos extremos de alto faturamento.

**Explora√ß√£o Anal√≠tica (EDA)**
"""

# --- 2.1 Domic√≠lios por classes sociais
# Distribui√ß√£o da popula√ß√£o por faixas et√°rias

classes = ["domiciliosA1","domiciliosA2","domiciliosB1","domiciliosB2",
           "domiciliosC1","domiciliosC2","domiciliosD","domiciliosE"]
classes_exist = [c for c in classes if c in Base_Dados.columns]

if classes_exist:
    domicilios = Base_Dados[classes_exist].sum().sort_index()
    plt.figure()
    domicilios.plot(kind="bar", edgecolor="black")
    plt.title("Distribui√ß√£o de domic√≠lios por classes sociais (total do dataset)", fontsize=14, fontweight="bold")
    plt.ylabel("N√∫mero de domic√≠lios")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# --- 2.2 Distribui√ß√£o de renda e faturamento
for col in ["rendaMedia", "faturamento"]:
    if col in Base_Dados.columns:
        plt.figure()
        sns.histplot(Base_Dados[col].dropna(), kde=True)
        ttl = "Renda M√©dia" if col=="rendaMedia" else "Faturamento"
        plt.title(f"Distribui√ß√£o de {ttl}", fontsize=14, fontweight="bold")
        plt.tight_layout()
        plt.show()

# --- 2.3 Distribui√ß√£o de domic√≠lios por classes sociais

classes = ["domiciliosA1","domiciliosA2","domiciliosB1","domiciliosB2",
           "domiciliosC1","domiciliosC2","domiciliosD","domiciliosE"]

domicilios = Base_Dados[classes].sum().sort_index()

plt.figure(figsize=(10,6))
domicilios.plot(kind="bar", color="orange", edgecolor="black")
plt.title("Distribui√ß√£o de domic√≠lios por classes sociais (total do dataset)")
plt.ylabel("N√∫mero de domic√≠lios")
plt.xticks(rotation=45)
plt.show()

"""### 2.4 Boxplots (Detec√ß√£o de Outliers)
(Boxplots para faturamento e renda).  

**Descri√ß√£o:**  
> Foram identificados outliers principalmente no faturamento. Esses valores, embora extremos, s√£o mantidos pois refletem bairros com padr√µes distintos de consumo.

"""

from scipy.stats import chi2_contingency

# --- 2.4 Correla√ß√£o entre vari√°veis num√©ricas (Pearson)
num_cols = Base_Dados.select_dtypes(include=np.number).columns
if len(num_cols) > 1:
    corr_pearson = Base_Dados[num_cols].corr(method="pearson")

    plt.figure(figsize=(10,8))
    sns.heatmap(corr_pearson, annot=True, cmap="coolwarm", fmt=".2f", center=0)
    plt.title("Correla√ß√£o de Pearson (vari√°veis num√©ricas)", fontsize=14, fontweight="bold")
    plt.tight_layout()
    plt.show()

# --- Fun√ß√£o para Cram√©r‚Äôs V (associa√ß√£o entre categ√≥ricas)
def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2/n
    r, k = confusion_matrix.shape
    phi2corr = max(0, phi2 - (k-1)*(r-1)/(n-1))
    rcorr = r - (r-1)**2/(n-1)
    kcorr = k - (k-1)**2/(n-1)
    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))

# --- 2.5 Associa√ß√£o entre vari√°veis categ√≥ricas (Cram√©r‚Äôs V)
cat_cols = Base_Dados.select_dtypes(exclude=np.number).columns
if len(cat_cols) > 1:
    cramers_results = pd.DataFrame(index=cat_cols, columns=cat_cols, dtype=float)
    for col1 in cat_cols:
        for col2 in cat_cols:
            if col1 != col2:
                cramers_results.loc[col1, col2] = cramers_v(Base_Dados[col1], Base_Dados[col2])
            else:
                cramers_results.loc[col1, col2] = 1.0

    plt.figure(figsize=(8,6))
    sns.heatmap(cramers_results.astype(float), annot=True, cmap="Purples", fmt=".2f")
    plt.title("Associa√ß√£o entre vari√°veis categ√≥ricas (Cram√©r‚Äôs V)", fontsize=14, fontweight="bold")
    plt.tight_layout()
    plt.show()

# Tratar valores ausentes na rendaMedia (se for necess√°rio)
# Usar a mediana √© mais robusto a outliers do que a m√©dia
Base_Dados['rendaMedia'].fillna(Base_Dados['rendaMedia'].median(), inplace=True)

print("\n--- Antes do Tratamento de Outliers ---")
print(Base_Dados.describe())

# ===============================================
# Identifica√ß√£o e Tratamento de Outliers (M√©todo IQR)
# ===============================================

# Colunas num√©ricas para verificar outliers (excluindo 'codigo' e 'faturamento' por serem IDs/target)
# Inclua outras colunas de popula√ß√£o/domic√≠lios se desejar
numerical_cols = [
    'populacao', 'popAte9', 'popDe10a14', 'popDe15a19', 'popDe20a24',
    'popDe25a34', 'popDe35a49', 'popDe50a59', 'popMaisDe60',
    'domiciliosA1', 'domiciliosA2', 'domiciliosB1', 'domiciliosB2',
    'domiciliosC1', 'domiciliosC2', 'domiciliosD', 'domiciliosE',
    'rendaMedia'
]

# Tamb√©m verificar outliers na vari√°vel alvo 'faturamento'
# Embora geralmente n√£o se trate outliers no target, √© bom identificar
# e entender sua distribui√ß√£o.
# Para o faturamento, vamos apenas identificar, n√£o limitar, pois √© o que queremos prever.

def cap_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Contar outliers antes do tratamento
    outliers_count = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]
    print(f"Coluna '{column}': {outliers_count} outliers identificados.")

    # Limitar os valores (capping)
    df.loc[df[column] < lower_bound, column] = lower_bound
    df.loc[df[column] > upper_bound, column] = upper_bound
    return df

# Aplicar o tratamento de outliers para as colunas selecionadas
for col in numerical_cols:
    Base_Dados = cap_outliers_iqr(Base_Dados, col) # Usar .copy() para evitar SettingWithCopyWarning

# Identificar outliers no faturamento (apenas para observa√ß√£o)
Q1_fat = Base_Dados['faturamento'].quantile(0.25)
Q3_fat = Base_Dados['faturamento'].quantile(0.75)
IQR_fat = Q3_fat - Q1_fat
lower_bound_fat = Q1_fat - 1.5 * IQR_fat
upper_bound_fat = Q3_fat + 1.5 * IQR_fat
outliers_fat_count = Base_Dados[(Base_Dados['faturamento'] < lower_bound_fat) | (Base_Dados['faturamento'] > upper_bound_fat)].shape[0]
print(f"Coluna 'faturamento': {outliers_fat_count} outliers identificados (n√£o tratados).")

print("\n--- Ap√≥s o Tratamento de Outliers (Capping) ---")
print(Base_Dados.describe())

# Opcional: Visualizar a distribui√ß√£o ap√≥s o tratamento

plt.figure(figsize=(12, 6))
sns.histplot(Base_Dados['rendaMedia'], kde=True)
# ## Descri√ß√£o: A distribui√ß√£o da renda m√©dia apresenta assimetria, com cauda √† direita...
plt.title('Distribui√ß√£o de renda m√©dia ap√≥s tratamento de outliers')
plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(Base_Dados['faturamento'], kde=True)
# ## Descri√ß√£o: A distribui√ß√£o do faturamento mostra maioria concentrada em valores baixos/m√©dios, com alguns outliers altos...
plt.title('Distribui√ß√£o de faturamento (outliers identificados, mas n√£o limitados)')
plt.show()

"""###Explica√ß√£o:

1.
Tratamento de Valores Ausentes: Antes de tratar outliers, √© importante lidar com valores ausentes. Substitu√≠ a m√©dia pela mediana para preencher os NaN em rendaMedia, pois a mediana √© menos sens√≠vel a outliers e pode fornecer uma imputa√ß√£o mais representativa.

2.
Identifica√ß√£o IQR: Para cada coluna num√©rica, calculamos o primeiro quartil (Q1), o terceiro quartil (Q3) e o Intervalo Interquartil (IQR = Q3 - Q1). Os limites inferior e superior para outliers s√£o definidos como Q1 - 1.5 * IQR e Q3 + 1.5 * IQR, respectivamente.

3.
Capping (Limita√ß√£o): Em vez de remover as linhas com outliers (o que pode reduzir significativamente o tamanho do dataset), optamos por limitar os valores. Isso significa que qualquer valor abaixo do limite inferior √© substitu√≠do pelo limite inferior, e qualquer valor acima do limite superior √© substitu√≠do pelo limite superior. Isso ajuda a reduzir o impacto dos outliers sem perder dados.

4.
Vari√°vel Alvo (faturamento): Para a vari√°vel alvo, os outliers s√£o apenas identificados para sua compreens√£o, mas n√£o s√£o limitados. Geralmente, n√£o se trata outliers na vari√°vel que se deseja prever, a menos que haja um erro claro nos dados.

5.
Visualiza√ß√£o: Os histogramas ap√≥s o tratamento ajudam a visualizar como a distribui√ß√£o dos dados foi alterada, mostrando uma concentra√ß√£o maior dos valores dentro dos limites definidos.
"""

# --- Criar FLAG de valores nulos antes da imputa√ß√£o ---
if "rendaMedia" in Base_Dados.columns:
    Base_Dados["rendaMedia_missing"] = Base_Dados["rendaMedia"].isna().astype(int)

    # Agora sim, preencher os NaN pela mediana
    Base_Dados["rendaMedia"].fillna(Base_Dados["rendaMedia"].median(), inplace=True)

    print("‚úÖ Flag 'rendaMedia_missing' criada (1 = valor imputado, 0 = valor original).")
    print(Base_Dados["rendaMedia_missing"].value_counts())

# --- 2.5 Correla√ß√£o
num_cols = Base_Dados.select_dtypes(include="number").columns
if len(num_cols) > 1:
    corr = Base_Dados[num_cols].corr()
    plt.figure(figsize=(10,8))
    sns.heatmap(corr, annot=False, cmap="coolwarm", center=0)
# ## Descri√ß√£o: O heatmap de correla√ß√£o destaca rendaMedia e popula√ß√£o total como mais correlacionadas ao faturamento...
    plt.title("Matriz de Correla√ß√£o (vari√°veis num√©ricas)", fontsize=14, fontweight="bold")
    plt.tight_layout()
    plt.show()

    if "faturamento" in corr.columns:
        top_corr = corr["faturamento"].drop("faturamento").sort_values(ascending=False)
        print("\nCorrela√ß√£o com 'faturamento' (top 10):")
        display(top_corr.head(10))

#--- 2.6 Histograma do target
plt.figure(figsize=(6,4))
sns.histplot(Base_Dados['faturamento'], kde=True)
# ## Descri√ß√£o: A distribui√ß√£o do faturamento mostra maioria concentrada em valores baixos/m√©dios, com alguns outliers altos...
plt.title("Distribui√ß√£o do faturamento")
plt.show()

"""### 2.5 Heatmap de Correla√ß√£o
(Heatmap entre vari√°veis).  

**Descri√ß√£o:**  
> A an√°lise de correla√ß√£o mostra que a renda m√©dia e a popula√ß√£o total possuem forte correla√ß√£o positiva com o faturamento.

"""

#--- 2.7 Correla√ß√£o entre features num√©ricas
# Selecionar apenas colunas num√©ricas
num_cols = Base_Dados.select_dtypes(include=np.number)

# Plotar heatmap de correla√ß√£o
plt.figure(figsize=(10,8))
sns.heatmap(num_cols.corr(), annot=True, fmt=".2f", cmap="coolwarm")
# ## Descri√ß√£o: O heatmap de correla√ß√£o destaca rendaMedia e popula√ß√£o total como mais correlacionadas ao faturamento...
plt.title("Mapa de correla√ß√£o (somente num√©ricas)")
plt.show()

# --- 2.8 Perguntas (Insights)
# --- Lista de faixas et√°rias ---
idades = ["popAte9","popDe10a14","popDe15a19","popDe20a24",
          "popDe25a34","popDe35a49","popDe50a59","popMaisDe60"]

# --- 1. Qual faixa et√°ria tem maior impacto no faturamento? ---
# Correla√ß√£o entre idade e faturamento
idade_corr = Base_Dados[idades + ["faturamento"]].corr()["faturamento"].sort_values(ascending=False)
print("Correla√ß√£o da faixa et√°ria com faturamento:")
print(idade_corr)

# --- 2. Quais classes de domic√≠lios se destacam em bairros de alto faturamento? ---
top_bairros = Base_Dados.sort_values("faturamento", ascending=False).head(10)
plt.figure(figsize=(10,6))
top_bairros_classes = top_bairros[classes].sum()
top_bairros_classes.plot(kind="bar", color="orange", edgecolor="black")
plt.title("Distribui√ß√£o de domic√≠lios em bairros com maior faturamento")
plt.ylabel("N√∫mero de domic√≠lios")
plt.xticks(rotation=45)
plt.show()

# --- 3. Bairros com renda m√©dia alta e faturamento baixo (oportunidade de expans√£o) ---
# Definindo um limiar baseado em percentis
renda_alta = Base_Dados["rendaMedia"].quantile(0.75)
faturamento_baixo = Base_Dados["faturamento"].quantile(0.25)

oportunidade = Base_Dados[(Base_Dados["rendaMedia"] >= renda_alta) &
                          (Base_Dados["faturamento"] <= faturamento_baixo)]

print("üìå Bairros com renda m√©dia alta e faturamento baixo (oportunidade de expans√£o):")
display(oportunidade[["nome","rendaMedia","faturamento"]])

# --- An√°lise categ√≥rica (bairro) ---
print("\nüìä Top 10 bairros por faturamento m√©dio:")
top10_bairros = Base_Dados.groupby('nome')['faturamento'].mean().sort_values(ascending=False).head(10)
print(top10_bairros)

# --- 4. Rela√ß√£o entre popula√ß√£o total e faturamento ---
plt.figure(figsize=(10,6))
sns.scatterplot(x="populacao", y="faturamento", data=Base_Dados)
# ## Descri√ß√£o: O scatterplot mostra correla√ß√£o positiva entre popula√ß√£o e faturamento, com dispers√£o...
plt.title("Rela√ß√£o entre popula√ß√£o total e faturamento")
plt.xlabel("Popula√ß√£o total")
plt.ylabel("Faturamento")
plt.show()

# C√°lculo da correla√ß√£o
corr_pop = Base_Dados[["populacao","faturamento"]].corr().iloc[0,1]
print(f"Correla√ß√£o entre popula√ß√£o total e faturamento: {corr_pop:.2f}")

# --- 5. Observa√ß√µes sobre distribui√ß√£o de renda ou domic√≠lios ---
# M√©dia de domic√≠lios por classe
media_domicilios = Base_Dados[classes].mean().sort_values(ascending=False)
print("M√©dia de domic√≠lios por classe social:")
display(media_domicilios)

# --- 6. M√©dia de renda por bairro
plt.figure(figsize=(10,6))
sns.histplot(Base_Dados["rendaMedia"].dropna(), kde=True, color="green")
# ## Descri√ß√£o: A distribui√ß√£o da renda m√©dia apresenta assimetria, com cauda √† direita...
plt.title("Distribui√ß√£o de renda m√©dia por domic√≠lio")
plt.xlabel("Renda m√©dia")
plt.ylabel("Frequ√™ncia")
plt.show()

"""### 3. Pr√©-Processamento
- Tratamento de valores ausentes (imputa√ß√£o pela m√©dia em `rendaMedia`).  
- Cria√ß√£o de novas features (ex.: popula√ß√£o total, percentual de domic√≠lios por classe social).  
- Divis√£o treino/teste.

**Descri√ß√£o:**  
> As vari√°veis derivadas aumentam a capacidade do modelo em capturar rela√ß√µes complexas, como a representatividade de faixas et√°rias no faturamento.

**Eng. De Features**
"""

# =====================================
# 3) Pr√©-processamento para Regress√£o
# =====================================
# Remover colunas categ√≥ricas irrelevantes para regress√£o
drop_if_exists = ["codigo","nome","cidade","estado"]
for c in drop_if_exists:
    if c in Base_Dados.columns:
        Base_Dados = Base_Dados.drop(columns=c)

# Criando faixas et√°rias agregadas
Base_Dados['popJovem'] = Base_Dados['popAte9'] + Base_Dados['popDe10a14'] + Base_Dados['popDe15a19']
Base_Dados['popAdulto'] = Base_Dados['popDe20a24'] + Base_Dados['popDe25a34'] + Base_Dados['popDe35a49']
Base_Dados['popIdoso'] = Base_Dados['popDe50a59'] + Base_Dados['popMaisDe60']

# Distribui√ß√£o de vari√°veis chave ----
fig, axs = plt.subplots(2, 2, figsize=(14,10))

sns.histplot(Base_Dados['popJovem'], kde=True, ax=axs[0,0], color='skyblue')
axs[0,0].set_title("Distribui√ß√£o de Popula√ß√£o Jovem")

sns.histplot(Base_Dados['popAdulto'], kde=True, ax=axs[0,1], color='lightgreen')
axs[0,1].set_title("Distribui√ß√£o de Popula√ß√£o Adulta")

sns.histplot(Base_Dados['popIdoso'], kde=True, ax=axs[1,0], color='salmon')
axs[1,0].set_title("Distribui√ß√£o de Popula√ß√£o Idosa")

sns.histplot(Base_Dados['rendaMedia'], kde=True, ax=axs[1,1], color='gold')
axs[1,1].set_title("Distribui√ß√£o da Renda M√©dia")

plt.tight_layout()
plt.show()

# Vari√°veis agregadas de idade
Base_Dados['popJovem'] = Base_Dados['popAte9'] + Base_Dados['popDe10a14'] + Base_Dados['popDe15a19']
Base_Dados['popAdulto'] = Base_Dados['popDe20a24'] + Base_Dados['popDe25a34'] + Base_Dados['popDe35a49']
Base_Dados['popIdoso'] = Base_Dados['popDe50a59'] + Base_Dados['popMaisDe60']

# Sele√ß√£o de features
features = [
    "popAte9","popDe10a14","popDe15a19","popDe20a24","popDe25a34",
    "popDe35a49","popDe50a59","popMaisDe60",
    "domiciliosA1","domiciliosA2","domiciliosB1","domiciliosB2",
    "domiciliosC1","domiciliosC2","domiciliosD","domiciliosE",
    "rendaMedia"
]

# Adicionar vari√°veis agregadas
features += ['popJovem', 'popAdulto', 'popIdoso']

# Filtrar colunas v√°lidas
features = [f for f in features if f in Base_Dados.columns]

X = Base_Dados[features]
y = Base_Dados["faturamento"]

# Preencher NaN
X = X.fillna(X.mean(numeric_only=True))
y = y.fillna(y.mean())

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE
)

"""## 4. Primeiros Testes de Modelos
### Modelos Avaliados:
- Regress√£o Linear  
- Decision Tree Regressor  
- Random Forest Regressor  

**Descri√ß√£o dos Resultados:**  
> Foram treinados tr√™s modelos. A Regress√£o Linear serve como baseline, enquanto a Random Forest se destaca pela robustez em capturar rela√ß√µes n√£o-lineares.

**Pr√© Processamento**
"""

# =====================================
# 4) Modelagem ‚Äî Pipelines - 3 Regress√µes
# =====================================
# 4.1 Regress√£o Linear
pipe_lr = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LinearRegression())
])

# 4.2 √Årvore de Decis√£o
pipe_dt = Pipeline([
    ("model", DecisionTreeRegressor(random_state=RANDOM_STATE, max_depth=10))
])

# 4.3 Random Forest
pipe_rf = Pipeline([
    ("model", RandomForestRegressor(random_state=RANDOM_STATE, n_estimators=400))
])

# 4.4 Pipeline
pipelines = {
    "Regress√£o Linear": pipe_lr,
    "√Årvore de Decis√£o": pipe_dt,
    "Random Forest": pipe_rf

}

# Treinar todos os modelos
for name, pipe in pipelines.items():
    pipe.fit(X_train, y_train)

"""## 5. Resultados Preliminares
### 5.1 M√©tricas por Modelo
(Tabela com R¬≤, MSE, RMSE e MAE).  

**Descri√ß√£o:**  
> A Random Forest apresentou o melhor R¬≤ e menor erro. A √Årvore de Decis√£o apresentou bom ajuste no treino, mas poss√≠vel overfitting em rela√ß√£o ao teste.

### 5.2 Import√¢ncia das Vari√°veis
(Gr√°fico de import√¢ncia das features no Random Forest).  

**Descri√ß√£o:**  
> A renda m√©dia e a popula√ß√£o total aparecem como as vari√°veis mais relevantes para prever faturamento, refor√ßando a hip√≥tese inicial.
"""

# =====================================
# 5) Avalia√ß√£o ‚Äî Teste, Treino e Cross-Validation
# =====================================
def avaliar_completa(pipe, X_train, y_train, X_test, y_test, nome):
    y_pred_train = pipe.predict(X_train)
    y_pred_test = pipe.predict(X_test)

    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
    mae_train = mean_absolute_error(y_train, y_pred_train)
    r2_train = r2_score(y_train, y_pred_train)

    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
    mae_test = mean_absolute_error(y_test, y_pred_test)
    r2_test = r2_score(y_test, y_pred_test)

    # Valida√ß√£o cruzada
    r2_cv = cross_val_score(pipe, X, y, cv=5, scoring='r2').mean()

    print(f"\n{name} ‚Äî M√©tricas:")
    print(f"Treino: R¬≤={r2_train:.3f} | RMSE={rmse_train:,.2f} | MAE={mae_train:,.2f}")
    print(f"Teste : R¬≤={r2_test:.3f} | RMSE={rmse_test:,.2f} | MAE={mae_test:,.2f}")
    print(f"CV 5-fold R¬≤ m√©dio = {r2_cv:.3f}")

    return r2_cv

# Avaliar todos os modelos
cv_scores = {}
for name, pipe in pipelines.items():
    cv_scores[name] = avaliar_completa(pipe, X_train, y_train, X_test, y_test, name)

# =====================================
# 6) Escolher modelo mais robusto (CV R¬≤)
# =====================================
best_name = max(cv_scores, key=cv_scores.get)
best_pipe = pipelines[best_name]
print(f"\n‚ñ∫ Modelo escolhido (maior R¬≤ m√©dio CV): {best_name}")

# =====================================
# 7) Import√¢ncia das features
# =====================================
if best_name == "Random Forest":
    importances = best_pipe.named_steps["model"].feature_importances_
elif best_name == "√Årvore de Decis√£o":
    importances = best_pipe.named_steps["model"].feature_importances_
else:  # Linear Regression
    importances = best_pipe.named_steps["model"].coef_

feature_importance = pd.Series(importances, index=features).sort_values()
plt.figure(figsize=(8, max(4, 0.4*len(features))))
feature_importance.plot(kind="barh")
plt.title(f"Import√¢ncia das vari√°veis ‚Äî {best_name}", fontsize=14, fontweight="bold")
plt.xlabel("Valor")
plt.tight_layout()
plt.show()

# =====================================
# 8) Gr√°fico Real x Previsto com m√©tricas
# =====================================
y_pred_best = best_pipe.predict(X_test)

# Calcular m√©tricas do teste
r2_test = r2_score(y_test, y_pred_best)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_best))
mae_test = mean_absolute_error(y_test, y_pred_best)

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred_best, alpha=0.7)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         linestyle="--", color="red")

plt.title(f"Real vs Previsto ‚Äî {best_name}\n"
          f"R¬≤={r2_test:.3f} | RMSE={rmse_test:,.2f} | MAE={mae_test:,.2f}",
          fontsize=14, fontweight="bold")
plt.xlabel("Faturamento Real")
plt.ylabel("Faturamento Previsto")
plt.tight_layout()
plt.show()

# =====================================
# 9) Previs√£o para novos bairros
# =====================================
novos_bairros = pd.DataFrame({
    "popAte9": [1200, 800],
    "popDe10a14": [700, 500],
    "popDe15a19": [650, 450],
    "popDe20a24": [900, 700],
    "popDe25a34": [1500, 1200],
    "popDe35a49": [2000, 1800],
    "popDe50a59": [800, 600],
    "popMaisDe60": [500, 400],
    "domiciliosA1": [50, 30],
    "domiciliosA2": [100, 80],
    "domiciliosB1": [200, 150],
    "domiciliosB2": [250, 200],
    "domiciliosC1": [300, 250],
    "domiciliosC2": [350, 300],
    "domiciliosD": [150, 120],
    "domiciliosE": [50, 40],
    "rendaMedia": [7000, 5500]
})

# Preencher valores ausentes com a m√©dia do dataset original
novos_bairros = novos_bairros.fillna(X.mean())

# Criar as mesmas features derivadas que o modelo espera
novos_bairros["popJovem"] = novos_bairros["popAte9"] + novos_bairros["popDe10a14"] + novos_bairros["popDe15a19"] + novos_bairros["popDe20a24"]
novos_bairros["popAdulto"] = novos_bairros["popDe25a34"] + novos_bairros["popDe35a49"] + novos_bairros["popDe50a59"]
novos_bairros["popIdoso"] = novos_bairros["popMaisDe60"]

# Selecionar apenas as features usadas no modelo
features_modelo = X.columns  # garantir que as colunas est√£o na mesma ordem
novos_bairros_final = novos_bairros[features_modelo]

# Previs√£o
pred_faturamento = best_pipe.predict(novos_bairros_final)
print("\nPrevis√£o de faturamento para novos bairros:")
print(pred_faturamento)

# =====================================================
# 10. Salvar modelo corretamente
# =====================================================
import joblib

joblib.dump(best_pipe, "modelo_random_forest.pkl")
print("Modelo salvo em modelo_random_forest.pkl")

# =====================================================
# 11. Para carregar e usar o modelo salvo:
# =====================================================
modelo_carregado = joblib.load("modelo_random_forest.pkl")

# Fazer previs√µes
pred_novos = modelo_carregado.predict(novos_bairros_final)
print(pred_novos)

# =====================================================
# 12) Gerar Relat√≥rio Executivo em PDF com FPDF2 (UTF-8)
# =====================================================
!apt-get install -y fonts-dejavu
!pip install fpdf2

from fpdf import FPDF
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Apenas para garantir que os gr√°ficos foram salvos no disco
# Rode estas partes do seu notebook antes de gerar o PDF

# Salvar gr√°fico de barras da import√¢ncia das features
feature_importance.plot(kind="barh")
plt.title(f"Import√¢ncia das vari√°veis ‚Äî {best_name}", fontsize=14, fontweight="bold")
plt.xlabel("Valor")
plt.tight_layout()
plt.savefig("feature_importance.png")
plt.close()

# Salvar gr√°fico de Real vs Previsto
plt.scatter(y_test, y_pred_best, alpha=0.7)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         linestyle="--", color="red")
plt.title(f"Real vs Previsto ‚Äî {best_name}\n"
          f"R¬≤={r2_test:.3f} | RMSE={rmse_test:,.2f} | MAE={mae_test:,.2f}",
          fontsize=14, fontweight="bold")
plt.xlabel("Faturamento Real")
plt.ylabel("Faturamento Previsto")
plt.tight_layout()
plt.savefig("real_vs_previsto.png")
plt.close()


# In√≠cio da cria√ß√£o do PDF
pdf = FPDF()
pdf.add_page()
pdf.set_auto_page_break(auto=True, margin=15)

# Registrar DejaVu (Unicode)
pdf.add_font("DejaVu", "", "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", uni=True)
pdf.add_font("DejaVu", "B", "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", uni=True)


# T√≠tulo Principal
pdf.set_font("DejaVu", "B", 16)
pdf.cell(0, 10, "Relat√≥rio Executivo ‚Äì P√∫blico-Alvo e Previs√£o de Faturamento", ln=True, align="C")
pdf.ln(10)


# Se√ß√£o 1: Contexto e An√°lise dos Dados
pdf.set_font("DejaVu", "B", 14)
pdf.cell(0, 10, "1. An√°lise Explorat√≥ria dos Dados (EDA)", ln=True)
pdf.ln(2)
pdf.set_font("DejaVu", "", 12)
pdf.multi_cell(0, 8, "Nesta se√ß√£o, exploramos as caracter√≠sticas demogr√°ficas e econ√¥micas dos bairros para entender as rela√ß√µes com o faturamento.\n")
pdf.multi_cell(0, 8, "Observou-se uma forte correla√ß√£o entre renda m√©dia, popula√ß√£o e o faturamento.\n")

# Adicionar a tabela de correla√ß√£o (apenas as top 10)
pdf.ln(5)
pdf.set_font("DejaVu", "B", 12)
pdf.cell(0, 10, "Top 10 Correla√ß√µes com Faturamento:", ln=True)
pdf.set_font("DejaVu", "", 10)
top_corr = Base_Dados.corr()["faturamento"].drop("faturamento").sort_values(ascending=False).head(10)
for feature, corr_val in top_corr.items():
    pdf.cell(0, 6, f"{feature}: {corr_val:.2f}", ln=True)
pdf.ln(10)


# Se√ß√£o 2: Modelagem e Resultados
pdf.set_font("DejaVu", "B", 14)
pdf.cell(0, 10, "2. Modelagem e Resultados", ln=True)
pdf.ln(2)
pdf.set_font("DejaVu", "", 12)
pdf.multi_cell(0, 8, f"O modelo escolhido para a previs√£o de faturamento foi o **{best_name}** devido ao seu desempenho superior na valida√ß√£o cruzada.\n")
pdf.multi_cell(0, 8, f"As m√©tricas de avalia√ß√£o do modelo foram: R¬≤={r2_test:.3f}, RMSE={rmse_test:,.2f} e MAE={mae_test:,.2f}.\n")


# Inserir gr√°fico de Real vs Previsto
pdf.ln(5)
pdf.cell(0, 5, "Gr√°fico: Faturamento Real vs. Faturamento Previsto", ln=True, align="C")
pdf.image("real_vs_previsto.png", x=pdf.get_x() + 20, w=150)
pdf.ln(5)


# Inserir gr√°fico de Import√¢ncia das Features
pdf.cell(0, 5, "Gr√°fico: Import√¢ncia das Vari√°veis no Modelo", ln=True, align="C")
pdf.image("feature_importance.png", x=pdf.get_x() + 20, w=150)
pdf.ln(10)


# Se√ß√£o 3: Previs√£o de Faturamento
pdf.set_font("DejaVu", "B", 14)
pdf.cell(0, 10, "3. Previs√£o para Novos Bairros", ln=True)
pdf.ln(2)
pdf.set_font("DejaVu", "", 12)
pdf.multi_cell(0, 8, "Com base no modelo, realizamos a previs√£o de faturamento para os novos bairros:\n")
pdf.ln(5)

# Tabela de previs√£o
pdf.set_font("DejaVu", "B", 10)
pdf.cell(95, 8, "Bairro", border=1, align="C")
pdf.cell(95, 8, "Faturamento Previsto (R$)", border=1, ln=True, align="C")

pdf.set_font("DejaVu", "", 10)
for i, pred in enumerate(pred_faturamento):
    pdf.cell(95, 8, f"Bairro {i+1}", border=1, align="C")
    pdf.cell(95, 8, f"R$ {pred:,.2f}", border=1, ln=True, align="C")
pdf.ln(10)


# Finalizar e salvar PDF
pdf.output("Relatorio_Executivo_Geofusion.pdf")

"""No Google Colab, os arquivos que voc√™ gera ficam salvos no diret√≥rio de trabalho /content/.
No caso, o relat√≥rio foi salvo como:

bash

/content/Relatorio_Executivo_Geofusion.pdf

1) Pela barra lateral do Colab

Clique no √≠cone de pastinha no menu lateral esquerdo (normalmente √© o 3¬∫ √≠cone).

L√° vai aparecer o arquivo Relatorio_Executivo_Geofusion.pdf.

Clique com o bot√£o direito ‚Üí Download.

2) Usando c√≥digo abaixo para baixar

"""

# =====================================================
# 13) Baixar relat√≥rio
# =====================================================
from google.colab import files
files.download("Relatorio_Executivo_Geofusion.pdf")

